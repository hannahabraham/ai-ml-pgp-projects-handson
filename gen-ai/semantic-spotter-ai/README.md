# Semantic Spotter AI Project Insurance AI
Simplifying insurance document queries with the power of Retrieval-Augmented Generation (RAG), LlamaIndex, and state-of-the-art OpenAI GPT models.

## Project Overview
Semantic Spotter – RAG Insurance Assistant is a smart, user-centric solution designed to decode and simplify complex insurance documents using modern AI techniques. Instead of manually sifting through policy papers or legal jargon, users can ask natural language questions and receive quick, precise answers.

This assistant combines the retrieval capabilities of LlamaIndex with the generative power of GPT-4/Gemini, ensuring that responses are accurate, context-aware, and easy to understand.

## Benefits:
- **Instant Answers:** Get concise responses to complex insurance queries in seconds.
- **Human-Friendly Explanations:** Legal jargon is translated into plain English.
- **Scalable and Reliable:** Built to handle large volumes of data effortlessly.

**Example Use Cases:**
- "What is covered under my health insurance policy?"
- "What is accidental death policy"


## Features
🌟 **Smart Document Retrieval** – Uses LlamaIndex to pinpoint relevant text from documents.

🤖 **Context-Aware Answering** – Blends retrieval with LLMs (GPT-4, Gemini) for natural and accurate answers.

🔄 **ChromaDB Integration** – Fast, efficient storage and querying of document embeddings.

📄 **Supports Multiple Formats** – Works with PDFs, DOCX, and TXT files.

🧩 **Customizable Chunking** – Overlapping chunks enhance retrieval precision.

🌐 **Deploy Anywhere** – Local development or scalable cloud deployments supported.

🔐 **Secure & Private** – API keys securely managed, protecting sensitive insurance data.

📊 **Analytics Ready** – Optional analytics hooks to track and optimize usage.

💬 **Conversational Interface** – Natural interaction through a user-friendly question-answer format.

🚀 **Extensible Design** – Expandable to domains like law, healthcare, and finance.

## Tech Stack
- **Language**: Python-In Jupyter Notebook
- **Frameworks/Libraries**: Transformers, ChromaDB, Llama-Index, Disk Cache
- **APIs/Models**: OpenAI's GPT-4/ GPT-4o/ GPT-4o-mini or Gemini API or any other State-of-the-Art models
- **Tools used**: Jupyter Notebook

